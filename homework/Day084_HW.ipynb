{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day084_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fyO0n80pDsvj","colab_type":"text"},"source":["Work\n","\n","請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"]},{"cell_type":"code","metadata":{"id":"ED6EUQDNCyEM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"aed46575-40b6-4561-c87a-7ab097aca887","executionInfo":{"status":"ok","timestamp":1563933518638,"user_tz":-480,"elapsed":17487,"user":{"displayName":"黃馨儀","photoUrl":"https://lh3.googleusercontent.com/-wAPtGbsXMVo/AAAAAAAAAAI/AAAAAAAAEyc/b6juSxI-sqU/s64/photo.jpg","userId":"14933485723997940780"}}},"source":["import os\n","import keras\n","import itertools\n","# Disable GPU\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JoHMuk8GDxM4","colab_type":"code","colab":{}},"source":["train, test = keras.datasets.cifar10.load_data()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVZ9LSSIDxPg","colab_type":"code","colab":{}},"source":["## 資料前處理\n","def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCOLCXDLDxR7","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","# Preproc the inputs\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","# Preprc the outputs\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmZeBH5UDxUE","colab_type":"code","colab":{}},"source":["from keras.layers import BatchNormalization\n","\n","\"\"\"\n","建立神經網路，並加入 BN layer\n","\"\"\"\n","def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n","    input_layer = keras.layers.Input(input_shape)\n","    \n","    for i, n_units in enumerate(num_neurons):\n","        if i == 0:\n","            x = keras.layers.Dense(units=n_units, \n","                                   activation=\"relu\", \n","                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n","            x = BatchNormalization()(x)\n","        else:\n","            x = keras.layers.Dense(units=n_units, \n","                                   activation=\"relu\", \n","                                   name=\"hidden_layer\"+str(i+1))(x)\n","            x = BatchNormalization()(x)\n","    \n","    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n","    \n","    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IodcRN3RDxWW","colab_type":"code","colab":{}},"source":["\"\"\"Code Here\n","設定超參數\n","\"\"\"\n","LEARNING_RATE = 1e-3\n","EPOCHS = 10\n","BATCH_SIZE = [16, 32, 64, 128]\n","MOMENTUM = 0.95"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHBNHHgVDxZA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":751},"outputId":"46543b11-ae4e-4316-d36a-0e2d5858584f"},"source":["results = {}\n","\"\"\"Code Here\n","撰寫你的訓練流程並將結果用 dictionary 紀錄\n","\"\"\"\n","for batch_size in BATCH_SIZE:\n","    model = build_mlp(input_shape=x_train.shape[1:])\n","    model.summary()\n","    optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n","    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n","\n","    model.fit(x_train, y_train, \n","              epochs=EPOCHS, \n","              batch_size=batch_size, \n","              validation_data=(x_test, y_test), \n","              shuffle=True)\n","\n","    # Collect results    \n","    train_loss = model.history.history[\"loss\"]\n","    valid_loss = model.history.history[\"val_loss\"]\n","    train_acc = model.history.history[\"acc\"]\n","    valid_acc = model.history.history[\"val_acc\"]\n","    name_tag = 'batch_size_%d' % batch_size\n","    results[name_tag] = {'train-loss': train_loss,\n","                         'valid-loss': valid_loss,\n","                         'train-acc': train_acc,\n","                         'valid-acc': valid_acc}\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0724 01:59:14.239003 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0724 01:59:14.391438 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0724 01:59:14.444298 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0724 01:59:15.940670 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 256)               1024      \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,742,474\n","Trainable params: 1,740,682\n","Non-trainable params: 1,792\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["W0724 01:59:21.816146 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0724 01:59:21.970220 140374126303104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0724 01:59:25.808187 140374126303104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","  880/50000 [..............................] - ETA: 17:47 - loss: 2.3490 - acc: 0.2034"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1oKBttfJD9Yi","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\"\"\"Code Here\n","將結果繪出\n","\"\"\"\n","color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"c\"]\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]}]}