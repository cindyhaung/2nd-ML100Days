{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day079_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3FxBgVnj9sVb","colab_type":"text"},"source":["Work\n","\n","請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"]},{"cell_type":"code","metadata":{"id":"bBf5yCUd8Zyb","colab_type":"code","outputId":"11c095ac-7b5c-4b13-ead3-1b398149e73f","executionInfo":{"status":"ok","timestamp":1563933439834,"user_tz":-480,"elapsed":3718,"user":{"displayName":"黃馨儀","photoUrl":"https://lh3.googleusercontent.com/-wAPtGbsXMVo/AAAAAAAAAAI/AAAAAAAAEyc/b6juSxI-sqU/s64/photo.jpg","userId":"14933485723997940780"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import keras\n","\n","# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5LPiQwTg99C7","colab_type":"code","colab":{}},"source":["train, test = keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Udh5OYl99K5","colab_type":"code","colab":{}},"source":["## 資料前處理\n","def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzgW01gw99OV","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","# 資料前處理 - X 標準化\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","# 資料前處理 -Y 轉成 onehot\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7WliCA699Qw","colab_type":"code","colab":{}},"source":["def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n","    input_layer = keras.layers.Input(input_shape)\n","    \n","    for i, n_units in enumerate(num_neurons):\n","        if i == 0:\n","            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n","        else:\n","            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n","    \n","    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n","    \n","    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQ8SrXdA-IH0","colab_type":"code","colab":{}},"source":["\"\"\"Code Here\n","設定超參數\n","\"\"\"\n","LEARNING_RATE = 0.01\n","EPOCHS = 50\n","BATCH_SIZE = 256\n","MOMENTUM = [0.95, 0.85, 0.75, 0.65, 0.55]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wn5WkcOB-IKg","colab_type":"code","outputId":"8c014b82-1289-468e-d30e-07fc864808b8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["results = {}\n","\"\"\"Code Here\n","撰寫你的訓練流程並將結果用 dictionary 紀錄\n","\"\"\"\n","for momentum in MOMENTUM:\n","    keras.backend.clear_session() # 把舊的 Graph 清掉\n","    print(\"Experiment with MOMENTUM = %.6f\" % (momentum))\n","    model = build_mlp(input_shape=x_train.shape[1:])\n","    model.summary()\n","    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=momentum)\n","    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n","\n","    model.fit(x_train, y_train, \n","              epochs=EPOCHS, \n","              batch_size=BATCH_SIZE, \n","              validation_data=(x_test, y_test), \n","              shuffle=True)\n","    \n","    # Collect results\n","    train_loss = model.history.history[\"loss\"]\n","    valid_loss = model.history.history[\"val_loss\"]\n","    train_acc = model.history.history[\"acc\"]\n","    valid_acc = model.history.history[\"val_acc\"]\n","    \n","    exp_name_tag = \"exp-momentum-%s\" % str(momentum)\n","    results[exp_name_tag] = {'train-loss': train_loss,\n","                             'valid-loss': valid_loss,\n","                             'train-acc': train_acc,\n","                             'valid-acc': valid_acc}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0724 01:57:24.651648 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","W0724 01:57:24.665520 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0724 01:57:24.700369 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0724 01:57:24.702583 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0724 01:57:24.717801 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0724 01:57:24.900590 140188832507776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Experiment with MOMENTUM = 0.950000\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,738,890\n","Trainable params: 1,738,890\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["W0724 01:57:25.115677 140188832507776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 29s 584us/step - loss: 1.8262 - acc: 0.3452 - val_loss: 1.7769 - val_acc: 0.3669\n","Epoch 2/50\n","50000/50000 [==============================] - 45s 898us/step - loss: 1.5950 - acc: 0.4347 - val_loss: 1.5413 - val_acc: 0.4503\n","Epoch 3/50\n","50000/50000 [==============================] - 62s 1ms/step - loss: 1.5029 - acc: 0.4657 - val_loss: 1.5288 - val_acc: 0.4504\n","Epoch 4/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 1.4358 - acc: 0.4895 - val_loss: 1.4693 - val_acc: 0.4719\n","Epoch 5/50\n","50000/50000 [==============================] - 49s 987us/step - loss: 1.3979 - acc: 0.5025 - val_loss: 1.4521 - val_acc: 0.4817\n","Epoch 6/50\n","50000/50000 [==============================] - 49s 988us/step - loss: 1.3548 - acc: 0.5188 - val_loss: 1.5142 - val_acc: 0.4692\n","Epoch 7/50\n","50000/50000 [==============================] - 49s 985us/step - loss: 1.3228 - acc: 0.5296 - val_loss: 1.4480 - val_acc: 0.4794\n","Epoch 8/50\n","50000/50000 [==============================] - 48s 969us/step - loss: 1.2942 - acc: 0.5408 - val_loss: 1.4121 - val_acc: 0.5009\n","Epoch 9/50\n","50000/50000 [==============================] - 48s 967us/step - loss: 1.2629 - acc: 0.5507 - val_loss: 1.4166 - val_acc: 0.4951\n","Epoch 10/50\n","50000/50000 [==============================] - 48s 952us/step - loss: 1.2312 - acc: 0.5648 - val_loss: 1.3946 - val_acc: 0.5113\n","Epoch 11/50\n","50000/50000 [==============================] - 48s 953us/step - loss: 1.2066 - acc: 0.5735 - val_loss: 1.3742 - val_acc: 0.5178\n","Epoch 12/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 1.1726 - acc: 0.5845 - val_loss: 1.3758 - val_acc: 0.5162\n","Epoch 13/50\n","50000/50000 [==============================] - 48s 967us/step - loss: 1.1522 - acc: 0.5890 - val_loss: 1.3567 - val_acc: 0.5166\n","Epoch 14/50\n","50000/50000 [==============================] - 48s 953us/step - loss: 1.1259 - acc: 0.5986 - val_loss: 1.3604 - val_acc: 0.5196\n","Epoch 15/50\n","50000/50000 [==============================] - 48s 963us/step - loss: 1.1026 - acc: 0.6084 - val_loss: 1.3613 - val_acc: 0.5214\n","Epoch 16/50\n","50000/50000 [==============================] - 48s 957us/step - loss: 1.0813 - acc: 0.6136 - val_loss: 1.4885 - val_acc: 0.4934\n","Epoch 17/50\n","50000/50000 [==============================] - 48s 965us/step - loss: 1.0538 - acc: 0.6247 - val_loss: 1.3739 - val_acc: 0.5261\n","Epoch 18/50\n","50000/50000 [==============================] - 48s 965us/step - loss: 1.0261 - acc: 0.6346 - val_loss: 1.3815 - val_acc: 0.5147\n","Epoch 19/50\n","50000/50000 [==============================] - 49s 975us/step - loss: 0.9984 - acc: 0.6444 - val_loss: 1.3912 - val_acc: 0.5256\n","Epoch 20/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 0.9756 - acc: 0.6527 - val_loss: 1.3860 - val_acc: 0.5336\n","Epoch 21/50\n","50000/50000 [==============================] - 48s 957us/step - loss: 0.9554 - acc: 0.6587 - val_loss: 1.5308 - val_acc: 0.5007\n","Epoch 22/50\n","50000/50000 [==============================] - 49s 979us/step - loss: 0.9225 - acc: 0.6688 - val_loss: 1.3847 - val_acc: 0.5302\n","Epoch 23/50\n","50000/50000 [==============================] - 50s 991us/step - loss: 0.8991 - acc: 0.6800 - val_loss: 1.4413 - val_acc: 0.5282\n","Epoch 24/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 0.8853 - acc: 0.6824 - val_loss: 1.4539 - val_acc: 0.5285\n","Epoch 25/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.8571 - acc: 0.6947 - val_loss: 1.4011 - val_acc: 0.5413\n","Epoch 26/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.8390 - acc: 0.7010 - val_loss: 1.4248 - val_acc: 0.5346\n","Epoch 27/50\n","50000/50000 [==============================] - 49s 971us/step - loss: 0.8100 - acc: 0.7109 - val_loss: 1.5091 - val_acc: 0.5234\n","Epoch 28/50\n","50000/50000 [==============================] - 49s 986us/step - loss: 0.7866 - acc: 0.7179 - val_loss: 1.5111 - val_acc: 0.5272\n","Epoch 29/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 0.7614 - acc: 0.7286 - val_loss: 1.5784 - val_acc: 0.5189\n","Epoch 30/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.7456 - acc: 0.7338 - val_loss: 1.5090 - val_acc: 0.5383\n","Epoch 31/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 0.7158 - acc: 0.7409 - val_loss: 1.5764 - val_acc: 0.5320\n","Epoch 32/50\n","50000/50000 [==============================] - 50s 997us/step - loss: 0.6970 - acc: 0.7502 - val_loss: 1.5732 - val_acc: 0.5334\n","Epoch 33/50\n","50000/50000 [==============================] - 50s 993us/step - loss: 0.6786 - acc: 0.7569 - val_loss: 1.5780 - val_acc: 0.5373\n","Epoch 34/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.6556 - acc: 0.7631 - val_loss: 1.6392 - val_acc: 0.5300\n","Epoch 35/50\n","50000/50000 [==============================] - 50s 990us/step - loss: 0.6373 - acc: 0.7727 - val_loss: 1.7003 - val_acc: 0.5337\n","Epoch 36/50\n","50000/50000 [==============================] - 49s 987us/step - loss: 0.6190 - acc: 0.7765 - val_loss: 1.6777 - val_acc: 0.5265\n","Epoch 37/50\n","50000/50000 [==============================] - 49s 979us/step - loss: 0.5981 - acc: 0.7848 - val_loss: 1.7441 - val_acc: 0.5288\n","Epoch 38/50\n","50000/50000 [==============================] - 48s 968us/step - loss: 0.5715 - acc: 0.7946 - val_loss: 1.7034 - val_acc: 0.5365\n","Epoch 39/50\n","50000/50000 [==============================] - 49s 984us/step - loss: 0.5410 - acc: 0.8056 - val_loss: 1.7962 - val_acc: 0.5361\n","Epoch 40/50\n","50000/50000 [==============================] - 49s 983us/step - loss: 0.5375 - acc: 0.8062 - val_loss: 1.8769 - val_acc: 0.5261\n","Epoch 41/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 0.5140 - acc: 0.8158 - val_loss: 1.8701 - val_acc: 0.5228\n","Epoch 42/50\n","50000/50000 [==============================] - 50s 999us/step - loss: 0.4986 - acc: 0.8200 - val_loss: 1.9778 - val_acc: 0.5241\n","Epoch 43/50\n","50000/50000 [==============================] - 49s 985us/step - loss: 0.4964 - acc: 0.8194 - val_loss: 1.9067 - val_acc: 0.5313\n","Epoch 44/50\n","50000/50000 [==============================] - 49s 981us/step - loss: 0.4768 - acc: 0.8279 - val_loss: 1.9897 - val_acc: 0.5197\n","Epoch 45/50\n","50000/50000 [==============================] - 49s 974us/step - loss: 0.4524 - acc: 0.8364 - val_loss: 1.9657 - val_acc: 0.5290\n","Epoch 46/50\n","50000/50000 [==============================] - 47s 947us/step - loss: 0.4264 - acc: 0.8464 - val_loss: 2.1258 - val_acc: 0.5207\n","Epoch 47/50\n","50000/50000 [==============================] - 49s 988us/step - loss: 0.4323 - acc: 0.8447 - val_loss: 2.1038 - val_acc: 0.5226\n","Epoch 48/50\n","50000/50000 [==============================] - 49s 986us/step - loss: 0.4169 - acc: 0.8497 - val_loss: 2.1844 - val_acc: 0.5175\n","Epoch 49/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 0.3986 - acc: 0.8572 - val_loss: 2.1708 - val_acc: 0.5143\n","Epoch 50/50\n","50000/50000 [==============================] - 49s 986us/step - loss: 0.3981 - acc: 0.8558 - val_loss: 2.1585 - val_acc: 0.5310\n","Experiment with MOMENTUM = 0.850000\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,738,890\n","Trainable params: 1,738,890\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 52s 1ms/step - loss: 1.8882 - acc: 0.3266 - val_loss: 1.7945 - val_acc: 0.3467\n","Epoch 2/50\n","50000/50000 [==============================] - 48s 967us/step - loss: 1.6831 - acc: 0.4042 - val_loss: 1.6890 - val_acc: 0.4052\n","Epoch 3/50\n","50000/50000 [==============================] - 46s 928us/step - loss: 1.5981 - acc: 0.4366 - val_loss: 1.7041 - val_acc: 0.3867\n","Epoch 4/50\n","50000/50000 [==============================] - 47s 932us/step - loss: 1.5374 - acc: 0.4593 - val_loss: 1.7604 - val_acc: 0.3881\n","Epoch 5/50\n","50000/50000 [==============================] - 49s 972us/step - loss: 1.4850 - acc: 0.4759 - val_loss: 1.7003 - val_acc: 0.4203\n","Epoch 6/50\n","50000/50000 [==============================] - 48s 960us/step - loss: 1.4474 - acc: 0.4889 - val_loss: 1.5461 - val_acc: 0.4485\n","Epoch 7/50\n","50000/50000 [==============================] - 47s 935us/step - loss: 1.4092 - acc: 0.5022 - val_loss: 1.6888 - val_acc: 0.4056\n","Epoch 8/50\n","50000/50000 [==============================] - 47s 948us/step - loss: 1.3812 - acc: 0.5113 - val_loss: 1.4482 - val_acc: 0.4803\n","Epoch 9/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 1.3485 - acc: 0.5210 - val_loss: 1.4747 - val_acc: 0.4749\n","Epoch 10/50\n","50000/50000 [==============================] - 47s 938us/step - loss: 1.3291 - acc: 0.5315 - val_loss: 1.3965 - val_acc: 0.5059\n","Epoch 11/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 1.2954 - acc: 0.5439 - val_loss: 1.5794 - val_acc: 0.4563\n","Epoch 12/50\n","50000/50000 [==============================] - 47s 947us/step - loss: 1.2801 - acc: 0.5484 - val_loss: 1.4756 - val_acc: 0.4771\n","Epoch 13/50\n","50000/50000 [==============================] - 48s 959us/step - loss: 1.2508 - acc: 0.5576 - val_loss: 1.4206 - val_acc: 0.5041\n","Epoch 14/50\n","50000/50000 [==============================] - 48s 967us/step - loss: 1.2304 - acc: 0.5662 - val_loss: 1.4185 - val_acc: 0.5024\n","Epoch 15/50\n","50000/50000 [==============================] - 49s 984us/step - loss: 1.2043 - acc: 0.5783 - val_loss: 1.4179 - val_acc: 0.5008\n","Epoch 16/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 1.1863 - acc: 0.5821 - val_loss: 1.4031 - val_acc: 0.5095\n","Epoch 17/50\n","50000/50000 [==============================] - 48s 967us/step - loss: 1.1577 - acc: 0.5916 - val_loss: 1.4336 - val_acc: 0.5048\n","Epoch 18/50\n","50000/50000 [==============================] - 48s 958us/step - loss: 1.1436 - acc: 0.5970 - val_loss: 1.4701 - val_acc: 0.4938\n","Epoch 19/50\n","50000/50000 [==============================] - 48s 965us/step - loss: 1.1206 - acc: 0.6038 - val_loss: 1.3888 - val_acc: 0.5226\n","Epoch 20/50\n","50000/50000 [==============================] - 49s 974us/step - loss: 1.1055 - acc: 0.6103 - val_loss: 1.3816 - val_acc: 0.5122\n","Epoch 21/50\n","50000/50000 [==============================] - 50s 993us/step - loss: 1.0840 - acc: 0.6180 - val_loss: 1.5097 - val_acc: 0.4866\n","Epoch 22/50\n","50000/50000 [==============================] - 49s 980us/step - loss: 1.0661 - acc: 0.6282 - val_loss: 1.4379 - val_acc: 0.5057\n","Epoch 23/50\n","50000/50000 [==============================] - 48s 966us/step - loss: 1.0412 - acc: 0.6331 - val_loss: 1.4403 - val_acc: 0.5036\n","Epoch 24/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 1.0272 - acc: 0.6370 - val_loss: 1.4009 - val_acc: 0.5240\n","Epoch 25/50\n","  256/50000 [..............................] - ETA: 41s - loss: 0.9022 - acc: 0.6680"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OO078-ay99Ti","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\"\"\"Code Here\n","將結果繪出\n","\"\"\"\n","color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\"]\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]}]}