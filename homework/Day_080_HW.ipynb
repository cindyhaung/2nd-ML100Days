{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day080_HW.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sAT0f7oR-iNT","colab_type":"text"},"source":["請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n","常見的 optimizer 包含\n","\n","SGD\n","\n","RMSprop\n","\n","AdaGrad\n","\n","Adam"]},{"cell_type":"code","metadata":{"id":"R2naHQHv-aSk","colab_type":"code","outputId":"242ec64d-1587-4cde-c173-5d8a45d8b821","executionInfo":{"status":"ok","timestamp":1563933544031,"user_tz":-480,"elapsed":22850,"user":{"displayName":"黃馨儀","photoUrl":"https://lh3.googleusercontent.com/-wAPtGbsXMVo/AAAAAAAAAAI/AAAAAAAAEyc/b6juSxI-sqU/s64/photo.jpg","userId":"14933485723997940780"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import keras\n","\n","# Disable GPU\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mQOCSAYS_N2P","colab_type":"code","colab":{}},"source":["train, test = keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-o0YAIyg_N67","colab_type":"code","colab":{}},"source":["## 資料前處理\n","def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiMbu1UX_N9l","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","# Preproc the inputs\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","# Preprc the outputs\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsiFGVKD_N_3","colab_type":"code","colab":{}},"source":["def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n","    input_layer = keras.layers.Input(input_shape)\n","    \n","    for i, n_units in enumerate(num_neurons):\n","        if i == 0:\n","            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n","        else:\n","            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n","    \n","    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n","    \n","    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-jvK46__OCY","colab_type":"code","colab":{}},"source":["## 超參數設定\n","\"\"\"\n","Set your required experiment parameters\n","\"\"\"\n","LEARNING_RATE = [0.01, 0.001]\n","OPTIMIZER = ['SGD', 'RMSprop', 'AdaGrad', 'Adam']\n","EPOCHS = 50\n","BATCH_SIZE = 256\n","MOMENTUM = 0.95"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VYPaqgd_XX_","colab_type":"code","outputId":"7ff6b357-7578-484a-efb9-fc193c37538b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["results = {}\n","\"\"\"\n","建立你的訓練與實驗迴圈並蒐集資料\n","\"\"\"\n","for lr in LEARNING_RATE:\n","    for opt in OPTIMIZER:\n","        keras.backend.clear_session() # 把舊的 Graph 清掉\n","        print(\"Experiment with lr = %.6f + OPT = %s\" % (lr, opt))\n","        model = build_mlp(input_shape=x_train.shape[1:])\n","        model.summary()\n","        if opt == 'SGD':\n","            optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n","        elif opt == 'RMSprop':\n","            optimizer = keras.optimizers.RMSprop(lr=lr)\n","        elif opt == 'AdaGrad':\n","            optimizer = keras.optimizers.Adagrad(lr=lr)\n","        elif opt == 'Adam':\n","            optimizer = keras.optimizers.Adam(lr=lr)\n","        model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n","\n","        model.fit(x_train, y_train, \n","                  epochs=EPOCHS, \n","                  batch_size=BATCH_SIZE, \n","                  validation_data=(x_test, y_test), \n","                  shuffle=True)\n","\n","        # Collect results\n","        train_loss = model.history.history[\"loss\"]\n","        valid_loss = model.history.history[\"val_loss\"]\n","        train_acc = model.history.history[\"acc\"]\n","        valid_acc = model.history.history[\"val_acc\"]\n","\n","        exp_name_tag = \"exp-lr-%s-opt-%s\" % (str(lr), opt)\n","        results[exp_name_tag] = {'train-loss': train_loss,\n","                                 'valid-loss': valid_loss,\n","                                 'train-acc': train_acc,\n","                                 'valid-acc': valid_acc}\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0724 01:59:35.459999 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","W0724 01:59:35.472182 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0724 01:59:35.602784 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0724 01:59:35.609971 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0724 01:59:35.630832 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Experiment with lr = 0.010000 + OPT = SGD\n"],"name":"stdout"},{"output_type":"stream","text":["W0724 01:59:36.377178 140317343057792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,738,890\n","Trainable params: 1,738,890\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["W0724 01:59:37.349831 140317343057792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 57s 1ms/step - loss: 1.8348 - acc: 0.3443 - val_loss: 1.7276 - val_acc: 0.3906\n","Epoch 2/50\n","50000/50000 [==============================] - 49s 983us/step - loss: 1.5981 - acc: 0.4351 - val_loss: 1.5979 - val_acc: 0.4350\n","Epoch 3/50\n","50000/50000 [==============================] - 50s 990us/step - loss: 1.5174 - acc: 0.4622 - val_loss: 1.4934 - val_acc: 0.4650\n","Epoch 4/50\n","50000/50000 [==============================] - 49s 984us/step - loss: 1.4493 - acc: 0.4857 - val_loss: 1.4702 - val_acc: 0.4702\n","Epoch 5/50\n","50000/50000 [==============================] - 49s 972us/step - loss: 1.4027 - acc: 0.5021 - val_loss: 1.4560 - val_acc: 0.4801\n","Epoch 6/50\n","50000/50000 [==============================] - 50s 999us/step - loss: 1.3643 - acc: 0.5183 - val_loss: 1.5200 - val_acc: 0.4655\n","Epoch 7/50\n","50000/50000 [==============================] - 49s 988us/step - loss: 1.3288 - acc: 0.5287 - val_loss: 1.4563 - val_acc: 0.4881\n","Epoch 8/50\n","50000/50000 [==============================] - 49s 985us/step - loss: 1.2933 - acc: 0.5389 - val_loss: 1.3848 - val_acc: 0.5114\n","Epoch 9/50\n","50000/50000 [==============================] - 49s 970us/step - loss: 1.2569 - acc: 0.5516 - val_loss: 1.4267 - val_acc: 0.4929\n","Epoch 10/50\n","50000/50000 [==============================] - 49s 981us/step - loss: 1.2274 - acc: 0.5642 - val_loss: 1.3783 - val_acc: 0.5131\n","Epoch 11/50\n","50000/50000 [==============================] - 49s 987us/step - loss: 1.1972 - acc: 0.5740 - val_loss: 1.3947 - val_acc: 0.5092\n","Epoch 12/50\n","50000/50000 [==============================] - 50s 994us/step - loss: 1.1702 - acc: 0.5821 - val_loss: 1.4706 - val_acc: 0.4841\n","Epoch 13/50\n","50000/50000 [==============================] - 49s 975us/step - loss: 1.1409 - acc: 0.5948 - val_loss: 1.3437 - val_acc: 0.5276\n","Epoch 14/50\n","50000/50000 [==============================] - 49s 974us/step - loss: 1.1205 - acc: 0.6015 - val_loss: 1.5045 - val_acc: 0.4848\n","Epoch 15/50\n","50000/50000 [==============================] - 49s 987us/step - loss: 1.0968 - acc: 0.6121 - val_loss: 1.3373 - val_acc: 0.5320\n","Epoch 16/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 1.0674 - acc: 0.6191 - val_loss: 1.3864 - val_acc: 0.5205\n","Epoch 17/50\n","50000/50000 [==============================] - 49s 977us/step - loss: 1.0442 - acc: 0.6278 - val_loss: 1.3494 - val_acc: 0.5281\n","Epoch 18/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 1.0189 - acc: 0.6382 - val_loss: 1.3587 - val_acc: 0.5267\n","Epoch 19/50\n","50000/50000 [==============================] - 49s 979us/step - loss: 0.9917 - acc: 0.6466 - val_loss: 1.3805 - val_acc: 0.5221\n","Epoch 20/50\n","50000/50000 [==============================] - 49s 981us/step - loss: 0.9715 - acc: 0.6514 - val_loss: 1.3839 - val_acc: 0.5307\n","Epoch 21/50\n","50000/50000 [==============================] - 50s 997us/step - loss: 0.9542 - acc: 0.6590 - val_loss: 1.4253 - val_acc: 0.5237\n","Epoch 22/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.9237 - acc: 0.6714 - val_loss: 1.3722 - val_acc: 0.5397\n","Epoch 23/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.9063 - acc: 0.6750 - val_loss: 1.4493 - val_acc: 0.5241\n","Epoch 24/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.8784 - acc: 0.6861 - val_loss: 1.4141 - val_acc: 0.5351\n","Epoch 25/50\n","50000/50000 [==============================] - 50s 992us/step - loss: 0.8545 - acc: 0.6927 - val_loss: 1.4272 - val_acc: 0.5373\n","Epoch 26/50\n","50000/50000 [==============================] - 50s 1ms/step - loss: 0.8301 - acc: 0.7012 - val_loss: 1.5426 - val_acc: 0.5229\n","Epoch 27/50\n","50000/50000 [==============================] - 50s 992us/step - loss: 0.8149 - acc: 0.7079 - val_loss: 1.4999 - val_acc: 0.5275\n","Epoch 28/50\n","50000/50000 [==============================] - 51s 1ms/step - loss: 0.7918 - acc: 0.7166 - val_loss: 1.5285 - val_acc: 0.5173\n","Epoch 29/50\n","50000/50000 [==============================] - 50s 992us/step - loss: 0.7691 - acc: 0.7235 - val_loss: 1.5098 - val_acc: 0.5407\n","Epoch 30/50\n","50000/50000 [==============================] - 49s 981us/step - loss: 0.7423 - acc: 0.7340 - val_loss: 1.5035 - val_acc: 0.5400\n","Epoch 31/50\n","50000/50000 [==============================] - 50s 997us/step - loss: 0.7136 - acc: 0.7429 - val_loss: 1.5349 - val_acc: 0.5312\n","Epoch 32/50\n","50000/50000 [==============================] - 49s 984us/step - loss: 0.6855 - acc: 0.7553 - val_loss: 1.5729 - val_acc: 0.5282\n","Epoch 33/50\n","50000/50000 [==============================] - 49s 987us/step - loss: 0.6622 - acc: 0.7636 - val_loss: 1.6485 - val_acc: 0.5313\n","Epoch 34/50\n","50000/50000 [==============================] - 50s 996us/step - loss: 0.6484 - acc: 0.7661 - val_loss: 1.6303 - val_acc: 0.5219\n","Epoch 35/50\n","50000/50000 [==============================] - 50s 992us/step - loss: 0.6262 - acc: 0.7748 - val_loss: 1.6088 - val_acc: 0.5397\n","Epoch 36/50\n","50000/50000 [==============================] - 48s 970us/step - loss: 0.6042 - acc: 0.7829 - val_loss: 1.8066 - val_acc: 0.5176\n","Epoch 37/50\n","50000/50000 [==============================] - 49s 985us/step - loss: 0.5858 - acc: 0.7897 - val_loss: 1.7479 - val_acc: 0.5309\n","Epoch 38/50\n","50000/50000 [==============================] - 50s 991us/step - loss: 0.5716 - acc: 0.7954 - val_loss: 1.7969 - val_acc: 0.5096\n","Epoch 39/50\n","50000/50000 [==============================] - 48s 964us/step - loss: 0.5555 - acc: 0.7999 - val_loss: 1.8479 - val_acc: 0.5153\n","Epoch 40/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 0.5373 - acc: 0.8082 - val_loss: 1.8306 - val_acc: 0.5254\n","Epoch 41/50\n","50000/50000 [==============================] - 49s 986us/step - loss: 0.5151 - acc: 0.8166 - val_loss: 1.8865 - val_acc: 0.5305\n","Epoch 42/50\n","50000/50000 [==============================] - 49s 979us/step - loss: 0.4897 - acc: 0.8239 - val_loss: 1.9402 - val_acc: 0.5256\n","Epoch 43/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 0.4771 - acc: 0.8288 - val_loss: 1.9016 - val_acc: 0.5279\n","Epoch 44/50\n","50000/50000 [==============================] - 49s 973us/step - loss: 0.4614 - acc: 0.8332 - val_loss: 2.0083 - val_acc: 0.5234\n","Epoch 45/50\n","50000/50000 [==============================] - 49s 971us/step - loss: 0.4444 - acc: 0.8403 - val_loss: 2.0397 - val_acc: 0.5158\n","Epoch 46/50\n","50000/50000 [==============================] - 50s 998us/step - loss: 0.4351 - acc: 0.8428 - val_loss: 2.0864 - val_acc: 0.5212\n","Epoch 47/50\n","50000/50000 [==============================] - 47s 946us/step - loss: 0.4250 - acc: 0.8458 - val_loss: 2.1612 - val_acc: 0.5194\n","Epoch 48/50\n","50000/50000 [==============================] - 50s 999us/step - loss: 0.4129 - acc: 0.8509 - val_loss: 2.2580 - val_acc: 0.5146\n","Epoch 49/50\n","50000/50000 [==============================] - 48s 958us/step - loss: 0.3899 - acc: 0.8608 - val_loss: 2.1884 - val_acc: 0.5296\n","Epoch 50/50\n","50000/50000 [==============================] - 51s 1ms/step - loss: 0.3826 - acc: 0.8622 - val_loss: 2.2723 - val_acc: 0.5192\n","Experiment with lr = 0.010000 + OPT = RMSprop\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 3072)              0         \n","_________________________________________________________________\n","hidden_layer1 (Dense)        (None, 512)               1573376   \n","_________________________________________________________________\n","hidden_layer2 (Dense)        (None, 256)               131328    \n","_________________________________________________________________\n","hidden_layer3 (Dense)        (None, 128)               32896     \n","_________________________________________________________________\n","output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,738,890\n","Trainable params: 1,738,890\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 57s 1ms/step - loss: 14.4457 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 2/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 3/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 4/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 5/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 6/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 7/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 8/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 9/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 10/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 11/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 12/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 13/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 14/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 15/50\n","50000/50000 [==============================] - 53s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 16/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 17/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 18/50\n","50000/50000 [==============================] - 55s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 19/50\n","50000/50000 [==============================] - 54s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 20/50\n","50000/50000 [==============================] - 47s 934us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 21/50\n","50000/50000 [==============================] - 52s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 22/50\n"," 2560/50000 [>.............................] - ETA: 44s - loss: 14.6007 - acc: 0.0941"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YQ698-Qs_chE","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\"\"\"Code Here\n","將結果繪出\n","\"\"\"\n","color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"c\", \"coral\", \"aqua\"]\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Accuracy\")\n","plt.legend()\n","plt.show()\n"],"execution_count":0,"outputs":[]}]}